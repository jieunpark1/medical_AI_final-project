{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c3bee0",
   "metadata": {},
   "source": [
    "## 0) 필요한 라이브러리 설치 및 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15104f7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q torchvision sklearn\n",
    "\n",
    "# import\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2e97e6",
   "metadata": {},
   "source": [
    "## 1) 캐글에서 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f89c45",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()  # kaggle.json\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
    "!unzip -q chest-xray-pneumonia.zip -d /content\n",
    "\n",
    "# 중복 제거 (있는 경우만)\n",
    "!mv /content/chest_xray/chest_xray/* /content/chest_xray/ 2>/dev/null\n",
    "!rm -r /content/chest_xray/chest_xray 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8fc794",
   "metadata": {},
   "source": [
    "## 1) eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c9ad0a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "csv_files = {\n",
    "    'train': '/content/DATA/csv/train_list.csv',\n",
    "    'val': '/content/DATA/csv/val_list.csv',\n",
    "    'test': '/content/DATA/csv/test_list.csv',\n",
    "}\n",
    "\n",
    "#각 split 별, label 별 historgram 살펴보기\n",
    "\n",
    "fig, axes = plt.subplots(nrow=3, ncols=1, figsize=(8, 12))\n",
    "fig.title('Histogram of CT image datasets', fontsize=16)\n",
    "colors = ['skyblue', 'orange']\n",
    "\n",
    "for idx, (split, path) in enumerate(csv_paths.items()):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    label_counts = df['label'].value_counts().sort_index()\n",
    "    \n",
    "    # 막대 차트 그리기\n",
    "    axes[idx].bar(['Normal (0)', 'Pneumonia (1)'], label_counts, color=colors)\n",
    "    axes[idx].set_title(f'{split} Set')\n",
    "    axes[idx].set_ylabel('Count')\n",
    "    axes[idx].set_ylim(0, max(label_counts) * 1.2)\n",
    "\n",
    "    # 개수 텍스트로 표시\n",
    "    for i, count in enumerate(label_counts):\n",
    "        axes[idx].text(i, count + 5, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb075c5e",
   "metadata": {},
   "source": [
    "- train 데이터의 불균형이 심하다. 따라서 augmentation을 통해 데이터 개수의 균형을 맞추는 것이 중요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290d22b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#미리 보기\n",
    "\n",
    "#train 각 label 별로 / val/test.. 2*3 형태로\n",
    "\n",
    "\n",
    "# Subplot: 3행 2열\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10, 10))\n",
    "axes = axes.flatten()  # 1차원 배열로 변환\n",
    "\n",
    "for split, path in csv_paths.items():\n",
    "    for lb in [\"NORMAL\", \"PNEUMONIA\"]:\n",
    "        df = pd.read_csv(path)\n",
    "        sample_df = df.loc[df.label == lb, ['path', 'label']]\n",
    "        \n",
    "        img_path = sample_df.loc[0, 'path']\n",
    "        label = sample_df.loc[0, 'label']\n",
    "        \n",
    "        # 이미지 불러오기\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        # 시각화\n",
    "        axes[i].imshow(image, cmap='gray')\n",
    "        axes[i].set_title(f'Label: {label}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb84b8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 이미지 크기 통계\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "sizes = []\n",
    "for path in tqdm(train_df['path'].values[:300]):  # 전체 말고 일부만 예시\n",
    "    try:\n",
    "        with Image.open(path) as img:\n",
    "            sizes.append(img.size)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "sizes = np.array(sizes)\n",
    "print(f\"Average size: {np.mean(sizes, axis=0)}\")\n",
    "\n",
    "# 분포 시각화\n",
    "plt.hist([w for w, h in sizes], bins=30, alpha=0.5, label='Width')\n",
    "plt.hist([h for w, h in sizes], bins=30, alpha=0.5, label='Height')\n",
    "plt.legend()\n",
    "plt.title(\"Image Size Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5fc0dc",
   "metadata": {},
   "source": [
    "## 2) 데이터 전처리 & 데이터 로더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2b55be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "✅ 해결 전략: 소수 클래스만 증강하기\n",
    "CSV에서 class 0만 filtering\n",
    "그 데이터만 augment해서 전체 train에 추가\n",
    "→ 결과적으로 class balance 맞춤\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 원본 train CSV 불러오기\n",
    "df = pd.read_csv(csv_files['train'])\n",
    "\n",
    "# 소수 클래스(예: label == 0)만 추출\n",
    "minority_df = df[df['label'] == 0]\n",
    "\n",
    "# 증강을 위해 minority 클래스 복사 (예: 2배로 증강)\n",
    "augmented_df = pd.concat([minority_df] * 2, ignore_index=True)\n",
    "\n",
    "# 합쳐서 class balance 맞추기\n",
    "balanced_train_df = pd.concat([df, augmented_df], ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# 4. CSV로 저장 → 모델 학습 시 사용\n",
    "balanced_train_df.to_csv('/content/DATA/csv/train_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73244ca3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class CSVImageDataset(Dataset):\n",
    "    def __init__(self, csv_path, transform=None, aug_transform_train_nml=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "        self.aug_transform_train_nml = aug_transform_train_nml\n",
    "        # 문자열 라벨을 숫자로 바꾸는 매핑\n",
    "        self.label_map = {'NORMAL': 0, 'PNEUMONIA': 1}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.df.iloc[idx]['path']\n",
    "        label_str = self.df.iloc[idx]['label']\n",
    "        label = self.label_map[label_str]\n",
    "\n",
    "        # 흑백 이미지 불러오기\n",
    "        image = Image.open(image_path).convert('L')\n",
    "\n",
    "        if label == 0 and self.aug_transform_train_nml:\n",
    "            image = self.aug_transform_train_nml(image)\n",
    "        elif self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34636eed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 이미지 변환 정의\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "aug_transform_train_nml = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b403c51",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = CSVImageDataset('/content/DATA/csv/train_list.csv', transform=transform_train, aug_transform_train_nml=aug_transform_train_nml)\n",
    "val_dataset = CSVImageDataset('/content/DATA/csv/val_list.csv', transform=transform_val)\n",
    "test_dataset = CSVImageDataset('/content/DATA/csv/test_list.csv', transform=transform_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ca00e",
   "metadata": {},
   "source": [
    "## 모델 구조 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18efd5a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class CNN_for_CT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * 28 * 28, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6269075e",
   "metadata": {},
   "source": [
    "## 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1f879",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch import optim\n",
    "from tqdm import tqdm  # 진행률 표시\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN_for_CT().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "train_loss_history = []\n",
    "\n",
    "epochs = 30\n",
    "patience = 5\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "    \n",
    "    for imgs, labels in progress_bar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = correct / total\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_correct, val_total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        val_correct += (predicted == labels).sum().item()\n",
    "        val_total += labels.size(0)\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader)\n",
    "    val_acc = val_correct / val_total\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"[{epoch+1}/{num_epochs}] \"\n",
    "    f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
    "    f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "        \n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "        torch.save(model.state_dict(), \"/content/MODELS/cnn_best_model.pth\")\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466dda1b",
   "metadata": {},
   "source": [
    "## 학습 과정 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dae41ff",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab015c4",
   "metadata": {},
   "source": [
    "## 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0655da7a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "model = model.load_state_dict(torch.load(\"/content/MODELS/cnn_best_model.pth\")).to(device)\n",
    "model.eval()\n",
    "y_true, y_pred, y_prob = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "        y_prob.extend(probs.cpu().numpy())\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_true, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_true, y_prob))\n",
    "\n",
    "# roc curve\n",
    "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Confusion Matrix 출력\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"NORMAL\", \"PNEUMONIA\"])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bdf202",
   "metadata": {},
   "source": [
    "## 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b4858",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 샘플 추출 및 예측 비교 시각화\n",
    "def visualize_predictions(model, dataset, num=5):\n",
    "    model.eval()\n",
    "    indices = np.random.choice(len(dataset), num, replace=False)\n",
    "    for idx in indices:\n",
    "        img, label = dataset[idx]\n",
    "        with torch.no_grad():\n",
    "            pred = model(img.unsqueeze(0).to(device))\n",
    "            pred_label = torch.argmax(pred).item()\n",
    "\n",
    "        plt.imshow(img.permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "        plt.title(f\"True: {'PNEUMONIA' if label==1 else 'NORMAL'} | Pred: {'PNEUMONIA' if pred_label==1 else 'NORMAL'}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "visualize_predictions(model, test_dataset, num=5)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
